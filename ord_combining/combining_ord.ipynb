{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa09ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc36c27d",
   "metadata": {},
   "source": [
    "# Combining Results in ORD\n",
    "\n",
    "This notebook provides a proof of concept example for combining catastrophe\n",
    "loss model results in the Open Results Data (ORD) format. We follow the\n",
    "methodology outlined in *Combining_results_in_ORD_v1.1.pdf*.\n",
    "\n",
    "This notebook is split into the workflow sequence as follows:\n",
    "\n",
    "1. Load and Group\n",
    "2. Period Sampling\n",
    "3. Loss Sampling\n",
    "4. Output Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678e3f3f-3294-4242-b677-03c290609e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "from dataclasses import asdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7d16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure relative imports work\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e9811",
   "metadata": {},
   "source": [
    "The input files are multiple runs of PiWind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5afa738d-f6a1-4ae6-8a6d-9d2b1a80eea2",
   "metadata": {
    "title": "specify input ORD dirs"
   },
   "outputs": [],
   "source": [
    "parent_path = Path().absolute().parent / 'piwind-ord'\n",
    "# parent_path = Path().absolute() / 'piwind-ord'\n",
    "\n",
    "ord_output_dirs = [parent_path / \"split/1/runs/losses-20251201164501/output/\",\n",
    "                   parent_path / \"split/2/runs/losses-20251201164618/output/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2568c4ac-4ac8-4651-b945-ee85295fe8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Path: combined_ord-091225153902\n"
     ]
    }
   ],
   "source": [
    "# specify directory for outputs\n",
    "\n",
    "output_dir = Path(\"./combined_ord-\" + datetime.now().strftime(\"%d%m%y%H%M%S\"))\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(f'Output Path: {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d002e65",
   "metadata": {},
   "source": [
    "## 1. Load and Group\n",
    "### Creating Analysis and OutputSet\n",
    "In this section we create the objects required prior to grouping, namely:\n",
    "- Analysis table which contains the meta data from the analyses\n",
    "- OutputSet table which contains references to the ORD results.\n",
    "\n",
    "\n",
    "The `analysis_settings.json` files for each ORD analysis are parsed to read the Analysis and OutputSet tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a4ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ord_combining.outputset import load_analysis_and_outputsets\n",
    "from ord_combining.common import dataclass_list_to_dataframe\n",
    "\n",
    "analysis, outputsets = load_analysis_and_outputsets(ord_output_dirs)\n",
    "\n",
    "# Convert to dict / df for remainder of notebook\n",
    "analysis = {a.id: a for a in analysis}\n",
    "outputsets_df = dataclass_list_to_dataframe(outputsets)\n",
    "\n",
    "outputsets_df['id'] = outputsets_df.index  # set id col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa78044-9b45-4c05-859a-05fc668a7dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>perspective_code</th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>exposure_summary_level_fields</th>\n",
       "      <th>exposure_summary_level_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gul</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gul</td>\n",
       "      <td>1</td>\n",
       "      <td>[LocNumber]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>gul</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>gul</td>\n",
       "      <td>2</td>\n",
       "      <td>[LocNumber]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id perspective_code  analysis_id exposure_summary_level_fields  \\\n",
       "0   0              gul            1                            []   \n",
       "1   1              gul            1                   [LocNumber]   \n",
       "2   2              gul            2                            []   \n",
       "3   3              gul            2                   [LocNumber]   \n",
       "\n",
       "   exposure_summary_level_id  \n",
       "0                          1  \n",
       "1                          2  \n",
       "2                          1  \n",
       "3                          2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputsets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8843b453-3d72-45fe-ae71-1b914264e346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'perspective_code', 'analysis_id',\n",
       "       'exposure_summary_level_fields', 'exposure_summary_level_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputsets_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccf1944",
   "metadata": {},
   "source": [
    "### Creating GroupEventSet\n",
    "The GroupEventSet are used to define common events, thereby allowing for a\n",
    "list of consistent unique events that can be used to create GroupPeriods.\n",
    "\n",
    "There is a config option `group_event_set_fields` which specifies which fields to use to specify the unique event.\n",
    "\n",
    "The EventOccurenceSet table contains the meta information for each event set based on the `group_event_set_fields`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d13901a-fa0d-40a1-8064-63a5a19d3aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full event occurrence set:\n",
      "   event_set_id event_occurrence_id model_supplier_id  analysis_id\n",
      "0            p                  lt          OasisLMF            1\n",
      "1            p                  lt          OasisLMF            2\n",
      "Event occurrence set:\n",
      "    event_occurrence_set_id event_set_id event_occurrence_id model_supplier_id\n",
      "0                        1            p                  lt          OasisLMF\n"
     ]
    }
   ],
   "source": [
    "from ord_combining.groupeventset import generate_group_set, generate_group_event_set\n",
    "group_event_set_fields = ['event_set_id', 'event_occurrence_id', 'model_supplier_id']\n",
    "\n",
    "group_set, group_output_set = generate_group_set(outputsets_df)\n",
    "event_occurrence_set_df, event_occurrence_set_analysis = generate_group_event_set(analysis, group_event_set_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed44e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 0, 3: 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_output_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b39994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>perspective_code</th>\n",
       "      <th>exposure_summary_level_fields_string</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_set_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gul</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gul</td>\n",
       "      <td>LocNumber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              group_id perspective_code exposure_summary_level_fields_string\n",
       "group_set_id                                                                \n",
       "0                    1              gul                                     \n",
       "1                    1              gul                            LocNumber"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb1dff92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_occurrence_set_id</th>\n",
       "      <th>event_set_id</th>\n",
       "      <th>event_occurrence_id</th>\n",
       "      <th>model_supplier_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>lt</td>\n",
       "      <td>OasisLMF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_occurrence_set_id event_set_id event_occurrence_id model_supplier_id\n",
       "0                        1            p                  lt          OasisLMF"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_occurrence_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1946c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>event_occurrence_set_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_id  event_occurrence_set_id\n",
       "0            1                        1\n",
       "1            2                        1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_occurrence_set_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce12d1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Once the groups have been assigned the SummaryId is aligned within each group_set.\n",
    "To do so we find each unique grouping of summary level fields in each group set and aggregate the tiv by summing.\n",
    "Then we produce a `outputset_summary_id_map` which contains dicts which maps\n",
    "the summary_id of the ORD files to the group `SummaryId` indexed by a key\n",
    "value of `output_set_id`.\n",
    "Note only adds mapping where summary_id != SummaryId\n",
    "\n",
    "To demo this swapped LocNumber for summary_id 1 and 2 in /home/vinulw/code/ODS_Tools/ord_combining/losses-20251021131718 SummaryLevel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "775cebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ord_combining.summaryinfo import load_summary_info, assign_summary_ids, generate_summary_id_map\n",
    "os_summary_info = load_summary_info(analysis, outputsets_df)\n",
    "group_set_summary_info = assign_summary_ids(group_output_set, os_summary_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45befd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {2: 3, 3: 6, 4: 9, 5: 10}, 3: {1: 2, 2: 4, 3: 5, 4: 7, 5: 8}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "outputset_summary_id_map = generate_summary_id_map(os_summary_info, group_set_summary_info, group_output_set)\n",
    "\n",
    "outputset_summary_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0fb2a29",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# save outputs\n",
    "with open(output_dir / 'analysis.json', 'w') as f:\n",
    "    _analysis_dict = {key: asdict(value) for key, value in analysis.items()}\n",
    "    json.dump(_analysis_dict, f, indent=4)\n",
    "\n",
    "with open(output_dir / 'group_output_set.json', 'w') as f:\n",
    "    json.dump(group_output_set, f, indent=4)\n",
    "\n",
    "group_set.to_csv(output_dir / 'group_set.csv')\n",
    "event_occurrence_set_analysis.to_csv(output_dir / 'group_event_set_analysis.csv', index=False)\n",
    "event_occurrence_set_df.to_csv(output_dir / 'event_occurrence_set.csv', index=False)\n",
    "\n",
    "outputsets_df.to_csv(output_dir / 'output_set.csv', index=False)\n",
    "\n",
    "# Serialise summary-info\n",
    "for gs, g_summary_info_df in group_set_summary_info.items():\n",
    "    gs_info = group_set.loc[gs]\n",
    "    summary_info_fname = f'{gs_info['perspective_code']}_GS{gs}_summary-info.csv'\n",
    "    g_summary_info_df.to_csv(output_dir / summary_info_fname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba805320",
   "metadata": {},
   "source": [
    "## 2. Period Sampling\n",
    "Now that each analysis has been grouped, we need to generate the GroupPeriods\n",
    "into which the events are assigned to for the combined output.\n",
    "\n",
    "We extract the Period for a given GroupEventSet that has a loss causing event\n",
    "and the total number of Periods. These Periods are then assigned to the\n",
    "GroupPeriod randomly, and if the total number of GroupPeriods is larger than\n",
    "the total number of Period then the GroupEventSet periods are cycled.\n",
    "\n",
    "The period information can be extracted from the header info of the `occurrence.bin` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f790ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ord_combining.groupperiod import generate_group_periods\n",
    "\n",
    "total_group_periods = 10000  # config: set by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34f64ea1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of group periods:  7620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinulw/code/ODS_Tools/env/lib/python3.12/site-packages/numba/typed/typeddict.py:39: NumbaTypeSafetyWarning: unsafe cast from int64 to int32. Precision may be lost.\n",
      "  return d[key]\n"
     ]
    }
   ],
   "source": [
    "group_event_set_analysis = event_occurrence_set_analysis.rename(columns={'event_occurrence_set_id': 'group_event_set_id'})\n",
    "\n",
    "group_period = generate_group_periods(group_event_set_analysis, analysis, total_group_periods)\n",
    "\n",
    "group_period.head()\n",
    "\n",
    "print('No. of group periods: ', len(group_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55f63842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv\n",
    "group_period.to_csv(output_dir / 'group_period.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaafb7b2",
   "metadata": {},
   "source": [
    "## 3. Loss Sampling\n",
    "The final step involves sampling losses for each event in the GroupPeriod.\n",
    "There are two types of loss sampling:\n",
    "- Mean only (only for MELT files)\n",
    "- Full uncertainty sampling\n",
    "\n",
    "The additional config options are demonstrated below. An example of a full config is:\n",
    "\n",
    "```python\n",
    "loss_sampling_config = {\n",
    "    \"group_mean\": False, # mean only\n",
    "    \"group_mean_type\": 1,  # SampleType filter\n",
    "    \"group_secondary_uncertainty\": False,\n",
    "    \"group_parametric_distribution\": 'gamma',  # either gamma or beta\n",
    "    \"group_format_priority\": [\"m\", \"q\", \"s\"}\n",
    "}\n",
    "```\n",
    "\n",
    "So far only `q` and `s` loss sampling are implemented. We output both mean only and full secondary uncertainty sampling below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85ef8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_format_priority = ['s']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb9e859",
   "metadata": {},
   "source": [
    "The first stage in loss sampling is generating the GroupPeriodQuantile table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c5473b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing group_event_set_id: 1,  outputset: 0\n",
      "Currently processing group_event_set_id: 1,  outputset: 1\n",
      "Currently processing group_event_set_id: 1,  outputset: 2\n",
      "Currently processing group_event_set_id: 1,  outputset: 3\n"
     ]
    }
   ],
   "source": [
    "from ord_combining.losssampling import construct_gpqt\n",
    "\n",
    "gpqt = construct_gpqt(group_period, group_event_set_analysis, outputsets_df, analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56d7210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save gpqt\n",
    "gpqt.to_csv(output_dir / \"gpqt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd8ed96",
   "metadata": {},
   "source": [
    "Finally the loss sampling can be done to produce the group period loss table (GPLT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7f488dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ord_combining.losssampling import do_loss_sampling_full_uncertainty, do_loss_sampling_mean_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfe4c610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running output_set_id: 0 - 1/4\n",
      "Could not perform loss sampling for 10700 events.\n",
      "Saved missing gpqt files to: combined_ord-091225153902/missing_gpqt_0.csv\n",
      "Running output_set_id: 1 - 2/4\n",
      "Could not perform loss sampling for 10700 events.\n",
      "Saved missing gpqt files to: combined_ord-091225153902/missing_gpqt_1.csv\n",
      "Running output_set_id: 2 - 3/4\n",
      "Could not perform loss sampling for 10700 events.\n",
      "Saved missing gpqt files to: combined_ord-091225153902/missing_gpqt_2.csv\n",
      "Running output_set_id: 3 - 4/4\n",
      "Could not perform loss sampling for 10700 events.\n",
      "Saved missing gpqt files to: combined_ord-091225153902/missing_gpqt_3.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_set_id</th>\n",
       "      <th>output_set_id</th>\n",
       "      <th>SummaryId</th>\n",
       "      <th>GroupPeriod</th>\n",
       "      <th>Period</th>\n",
       "      <th>group_event_set_id</th>\n",
       "      <th>EventId</th>\n",
       "      <th>Loss</th>\n",
       "      <th>LossType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>1094</td>\n",
       "      <td>116044.532845</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>1095</td>\n",
       "      <td>134083.190758</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>642</td>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>11385.682784</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>447</td>\n",
       "      <td>95285.146687</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>456</td>\n",
       "      <td>1</td>\n",
       "      <td>655</td>\n",
       "      <td>29433.598923</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_set_id  output_set_id  SummaryId  GroupPeriod  Period  \\\n",
       "0             0              0          1            2     756   \n",
       "1             0              0          1            2     756   \n",
       "2             0              0          1           10     642   \n",
       "3             0              0          1           12     319   \n",
       "4             0              0          1           15     456   \n",
       "\n",
       "   group_event_set_id  EventId           Loss  LossType  \n",
       "0                   1     1094  116044.532845         2  \n",
       "1                   1     1095  134083.190758         2  \n",
       "2                   1      919   11385.682784         2  \n",
       "3                   1      447   95285.146687         2  \n",
       "4                   1      655   29433.598923         2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# secondary uncertainty sampling\n",
    "gplt_full = do_loss_sampling_full_uncertainty(gpqt, outputsets_df,\n",
    "                                              group_output_set, analysis,\n",
    "                                              priority=group_format_priority,\n",
    "                                              outputset_summary_id_map=outputset_summary_id_map,\n",
    "                                              output_dir=output_dir)\n",
    "\n",
    "gplt_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a77b3b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output set 1 has 10700 missing SummaryIds.\n",
      "Output set 3 has 10700 missing SummaryIds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_set_id</th>\n",
       "      <th>output_set_id</th>\n",
       "      <th>SummaryId</th>\n",
       "      <th>GroupPeriod</th>\n",
       "      <th>Period</th>\n",
       "      <th>group_event_set_id</th>\n",
       "      <th>EventId</th>\n",
       "      <th>Loss</th>\n",
       "      <th>LossType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>677</td>\n",
       "      <td>1</td>\n",
       "      <td>975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>1094</td>\n",
       "      <td>198404.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>1094</td>\n",
       "      <td>167263.875000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>1095</td>\n",
       "      <td>99202.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>1095</td>\n",
       "      <td>62802.050781</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_set_id  output_set_id  SummaryId  GroupPeriod  Period  \\\n",
       "0             0              0       <NA>            1     677   \n",
       "1             0              0          1            2     756   \n",
       "2             0              0          1            2     756   \n",
       "3             0              0          1            2     756   \n",
       "4             0              0          1            2     756   \n",
       "\n",
       "   group_event_set_id  EventId           Loss  LossType  \n",
       "0                   1      975            NaN      <NA>  \n",
       "1                   1     1094  198404.000000         1  \n",
       "2                   1     1094  167263.875000         3  \n",
       "3                   1     1095   99202.000000         1  \n",
       "4                   1     1095   62802.050781         3  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean only sampling\n",
    "gplt_mean = do_loss_sampling_mean_only(gpqt, outputsets_df, group_output_set, analysis,\n",
    "                                       outputset_summary_id_map=outputset_summary_id_map)\n",
    "\n",
    "gplt_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acddc26c",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Output Generation\n",
    "The output options are:\n",
    "- Group Period Loss Table (GPLT)\n",
    "  - full (all group_set_id) <-- current implementation\n",
    "  - file based (each group_set_id in new file) <-- probably better\n",
    "- Group Average Loss Table (GALT)\n",
    "- Group Exceedance Probability Table (GEPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d365ccb2",
   "metadata": {},
   "source": [
    "### GPLT output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26d789b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_cols = ['group_set_id', 'output_set_id', 'SummaryId', 'GroupPeriod']\n",
    "gplt_full.sort_values(by=sort_cols).to_csv(output_dir / \"gplt_full.csv\", index=False)\n",
    "gplt_mean.sort_values(by=sort_cols).to_csv(output_dir / \"gplt_mean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5358c37c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from ord_combining.grouped_output import generate_al, generate_ep\n",
    "\n",
    "def save_output(full_df, output_dir, output_name, factor_col='group_set_id', float_format='%.6f'):\n",
    "    for i in full_df[factor_col].unique():\n",
    "        save_path = output_dir / f'{i}_{output_name}'\n",
    "        full_df.query(f\"{factor_col} == {i}\").to_csv(save_path, index=False,\n",
    "                                                     float_format=float_format)\n",
    "        print('Saved: ', save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d8cfd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### GALT Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad7ce79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:  combined_ord-091225153902/0_aal_full.csv\n",
      "Saved:  combined_ord-091225153902/1_aal_full.csv\n",
      "Saved:  combined_ord-091225153902/0_aal_mean.csv\n",
      "Saved:  combined_ord-091225153902/1_aal_mean.csv\n"
     ]
    }
   ],
   "source": [
    "dtypes_aal = {\n",
    "    'group_set_id': 'int',\n",
    "    'SummaryId': 'int',\n",
    "    'LossType': 'int',\n",
    "    'Mean': 'float',\n",
    "    'Std': 'float'\n",
    "}\n",
    "\n",
    "aal_full = generate_al(gplt_full, total_group_periods).astype(dtypes_aal)\n",
    "aal_mean = generate_al(gplt_mean, total_group_periods).astype(dtypes_aal)\n",
    "\n",
    "save_output(aal_full, output_dir, 'aal_full.csv')\n",
    "save_output(aal_mean, output_dir, 'aal_mean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ee3fb2",
   "metadata": {},
   "source": [
    "### GEPT Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "082b9f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:  combined_ord-091225153902/0_ep_full.csv\n",
      "Saved:  combined_ord-091225153902/1_ep_full.csv\n",
      "Saved:  combined_ord-091225153902/0_ep_mean.csv\n",
      "Saved:  combined_ord-091225153902/1_ep_mean.csv\n"
     ]
    }
   ],
   "source": [
    "dtypes_ep = {\n",
    "    'group_set_id': 'int',\n",
    "    'SummaryId': 'int',\n",
    "    'EPCalc': 'int',\n",
    "    'EPType': 'int',\n",
    "    'RP': 'float',\n",
    "    'Loss': 'float'\n",
    "}\n",
    "ep_full_df = generate_ep(gplt_full, total_group_periods, oep=True, aep=True).astype(dtypes_ep)\n",
    "ep_mean_df = generate_ep(gplt_mean, total_group_periods, oep=True, aep=True).astype(dtypes_ep)\n",
    "\n",
    "save_output(ep_full_df, output_dir, 'ep_full.csv')\n",
    "save_output(ep_mean_df, output_dir, 'ep_mean.csv')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
